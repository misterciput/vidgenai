{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üé¨ LoFi Video Generator - Quick Start\n",
        "\n",
        "Generate beautiful, seamlessly looping LoFi videos from static images using CogVideoX-5B-I2V.\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue)](https://github.com/misterciput/vidgenai)\n",
        "\n",
        "## üöÄ Features\n",
        "- üîÑ Perfect seamless loops\n",
        "- üé® Optimized for LoFi natural scenery\n",
        "- ‚ö° 10-15 minutes generation time\n",
        "- üíæ Memory efficient (fits in Colab's 15GB)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üõ†Ô∏è Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "check_gpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e255cce-b258-47a5-bcf0-a930feff9c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 13 11:49:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "clone_repo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a817dba-86b1-4b04-e28a-74f0837404bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vidgenai'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 32 (delta 10), reused 24 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (32/32), 15.45 KiB | 2.57 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "/content/vidgenai/vidgenai\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/misterciput/vidgenai.git\n",
        "%cd vidgenai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "install_requirements",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ecc41a-a792-4de2-ccca-f0a91cdcfff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.8.0+cu126)\n",
            "Requirement already satisfied: diffusers>=0.29.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (0.35.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (4.56.1)\n",
            "Requirement already satisfied: opencv-python>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (4.12.0.88)\n",
            "Requirement already satisfied: imageio>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.6.0)\n",
            "Requirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (1.10.1)\n",
            "Requirement already satisfied: xformers>=0.0.22 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (0.0.32.post2)\n",
            "Requirement already satisfied: bitsandbytes>=0.41.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (0.47.0)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (3.10.0)\n",
            "Requirement already satisfied: moviepy>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (1.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.29.0->-r requirements.txt (line 10)) (8.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.29.0->-r requirements.txt (line 10)) (0.34.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.29.0->-r requirements.txt (line 10)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.29.0->-r requirements.txt (line 10)) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.29.0->-r requirements.txt (line 10)) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->-r requirements.txt (line 11)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->-r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->-r requirements.txt (line 11)) (0.22.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.25.0->-r requirements.txt (line 23)) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 31)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 31)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 31)) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 31)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 31)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 31)) (2.9.0.post0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 34)) (0.1.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers>=0.29.0->-r requirements.txt (line 10)) (1.1.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 31)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers>=0.29.0->-r requirements.txt (line 10)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers>=0.29.0->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers>=0.29.0->-r requirements.txt (line 10)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers>=0.29.0->-r requirements.txt (line 10)) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers>=0.29.0->-r requirements.txt (line 10)) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 5)) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "import"
      },
      "source": [
        "## üì¶ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a2faf3-f173-4b25-ba21-3b9b950fd04f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 14.7 GB\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/vidgenai/src')\n",
        "\n",
        "from lofi_video_generator import LoFiVideoGenerator\n",
        "from google.colab import files\n",
        "import os\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload"
      },
      "source": [
        "## üì∑ Upload Your LoFi Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "upload_images",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "80f81a21-2368-4d4d-b105-665e3e40b79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Upload your LoFi landscape images (JPG, PNG):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1a172f1b-6d2d-45d8-bdcc-2af4092c3129\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1a172f1b-6d2d-45d8-bdcc-2af4092c3129\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving start_frame.png to start_frame.png\n",
            "\n",
            "‚úÖ Uploaded files:\n",
            "  üìÅ start_frame.png\n",
            "\n",
            "üìä Total images: 1\n"
          ]
        }
      ],
      "source": [
        "# Upload your LoFi images\n",
        "print(\"üì§ Upload your LoFi landscape images (JPG, PNG):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# List uploaded files\n",
        "print(\"\\n‚úÖ Uploaded files:\")\n",
        "image_files = []\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"  üìÅ {filename}\")\n",
        "    image_files.append(filename)\n",
        "\n",
        "print(f\"\\nüìä Total images: {len(image_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "initialize"
      },
      "source": [
        "## üé¨ Initialize Video Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "init_generator",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "outputId": "efac2f6f-f25c-4c13-feb3-d8bb7824808d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing VidGenAI Video Generator...\n",
            "Initializing LoFi Video Generator...\n",
            "Device: cuda\n",
            "Model: THUDM/CogVideoX-5b-I2V\n",
            "Memory optimization: True\n",
            "INT8 quantization: True\n",
            "üì• Loading CogVideoX-5B-I2V model...\n",
            "Loading CogVideoX-5B-I2V model...\n",
            "‚ùå Error loading model: auto not supported. Supported strategies are: balanced, cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "auto not supported. Supported strategies are: balanced, cuda",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2431643776.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the model (this will take a few minutes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üì• Loading CogVideoX-5B-I2V model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Generator ready!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vidgenai/src/lofi_video_generator.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# Load the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             self.pipe = CogVideoXImageToVideoPipeline.from_pretrained(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSUPPORTED_DEVICE_MAP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0;34mf\"{device_map} not supported. Supported strategies are: {', '.join(SUPPORTED_DEVICE_MAP)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: auto not supported. Supported strategies are: balanced, cuda"
          ]
        }
      ],
      "source": [
        "# Initialize the VidGenAI Video Generator\n",
        "print(\"üöÄ Initializing VidGenAI Video Generator...\")\n",
        "\n",
        "generator = LoFiVideoGenerator(\n",
        "    device=\"cuda\",\n",
        "    enable_memory_optimization=True,  # Essential for Colab\n",
        "    use_int8=True                    # Reduces memory usage\n",
        ")\n",
        "\n",
        "# Load the model (this will take a few minutes)\n",
        "print(\"üì• Loading CogVideoX-5B-I2V model...\")\n",
        "generator.load_model()\n",
        "\n",
        "print(\"‚úÖ Generator ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prompts"
      },
      "source": [
        "## üìù LoFi Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_prompts"
      },
      "outputs": [],
      "source": [
        "# Pre-defined LoFi prompts for natural scenery\n",
        "lofi_prompts = {\n",
        "    \"grass_field\": \"Gentle wind moving through tall grass, soft morning light, peaceful nature scene, subtle movement\",\n",
        "    \"water_scene\": \"Calm lake with small ripples, reflecting clouds slowly drifting by, serene atmosphere\",\n",
        "    \"forest\": \"Tree branches swaying gently in the breeze, dappled sunlight, tranquil forest scene\",\n",
        "    \"rain\": \"Soft rain drops creating ripples in a puddle, cozy rainy day atmosphere\",\n",
        "    \"sky\": \"Clouds slowly drifting across the sky, peaceful day, subtle movement\",\n",
        "    \"flowers\": \"Gentle flower petals swaying in a light breeze, soft natural lighting\",\n",
        "    \"mountains\": \"Misty mountains with slowly moving fog, peaceful morning atmosphere\",\n",
        "    \"beach\": \"Gentle waves lapping on the shore, soft sunset lighting, tranquil beach scene\"\n",
        "}\n",
        "\n",
        "# Common negative prompt\n",
        "negative_prompt = \"blurry, low quality, distorted, deformed, fast motion, jerky movement, unrealistic\"\n",
        "\n",
        "print(\"üìù Available prompt templates:\")\n",
        "for key, prompt in lofi_prompts.items():\n",
        "    print(f\"  üåø {key}: {prompt[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "single"
      },
      "source": [
        "## üé• Generate Single Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_single"
      },
      "outputs": [],
      "source": [
        "# Generate a single video (customize these settings)\n",
        "if image_files:\n",
        "    # Settings\n",
        "    selected_image = image_files[0]  # Use first uploaded image\n",
        "    selected_prompt = lofi_prompts[\"grass_field\"]  # Change this to match your image\n",
        "\n",
        "    print(f\"üé¨ Generating video for: {selected_image}\")\n",
        "    print(f\"üìù Prompt: {selected_prompt}\")\n",
        "    print(\"‚è∞ This will take 10-15 minutes...\")\n",
        "\n",
        "    # Generate video\n",
        "    output_path = generator.generate_lofi_video(\n",
        "        image_path=selected_image,\n",
        "        prompt=selected_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_frames=49,          # ~5 seconds at 10fps\n",
        "        fps=10,                 # LoFi aesthetic FPS\n",
        "        guidance_scale=6.0,     # Balance between prompt adherence and quality\n",
        "        num_inference_steps=50, # Quality vs speed trade-off\n",
        "        generator_seed=42,      # For reproducibility\n",
        "        output_path=\"lofi_video_single.mp4\"\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Video generated: {output_path}\")\n",
        "\n",
        "    # Download the video\n",
        "    files.download(output_path)\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Please upload images first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch"
      },
      "source": [
        "## üé¨ Generate Multiple Videos (Batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_batch"
      },
      "outputs": [],
      "source": [
        "# Generate multiple videos with different prompts\n",
        "if len(image_files) > 1:\n",
        "    # Customize prompts for each image\n",
        "    batch_prompts = [\n",
        "        lofi_prompts[\"grass_field\"],\n",
        "        lofi_prompts[\"water_scene\"],\n",
        "        lofi_prompts[\"forest\"],\n",
        "        lofi_prompts[\"sky\"],\n",
        "        lofi_prompts[\"flowers\"]\n",
        "    ]\n",
        "\n",
        "    # Use only as many prompts as we have images\n",
        "    num_videos = min(len(image_files), len(batch_prompts))\n",
        "    selected_images = image_files[:num_videos]\n",
        "    selected_prompts = batch_prompts[:num_videos]\n",
        "\n",
        "    print(f\"üé¨ Generating {num_videos} videos...\")\n",
        "    print(f\"‚è∞ Estimated time: {num_videos * 12} minutes\")\n",
        "\n",
        "    # Generate batch\n",
        "    output_paths = generator.generate_multiple_videos(\n",
        "        image_paths=selected_images,\n",
        "        prompts=selected_prompts,\n",
        "        output_dir=\"lofi_videos_batch\",\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_frames=49,\n",
        "        fps=10,\n",
        "        guidance_scale=6.0,\n",
        "        num_inference_steps=50,\n",
        "        generator_seed=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\n‚úÖ Generated {len(output_paths)} videos:\")\n",
        "    for i, path in enumerate(output_paths):\n",
        "        print(f\"  üé• {i+1}. {path}\")\n",
        "    \n",
        "    # Download all videos\n",
        "    print(\"\\nüì• Downloading videos...\")\n",
        "    for path in output_paths:\n",
        "        files.download(path)\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Upload multiple images for batch generation!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom"
      },
      "source": [
        "## üé® Custom Generation (Advanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom_generation"
      },
      "outputs": [],
      "source": [
        "# Custom generation with your own settings\n",
        "if image_files:\n",
        "    # Customize these settings\n",
        "    CUSTOM_IMAGE = image_files[0]  # Change index to select different image\n",
        "    CUSTOM_PROMPT = \"YOUR CUSTOM PROMPT HERE\"  # Write your own prompt\n",
        "    CUSTOM_NEGATIVE = \"blurry, low quality, distorted, fast motion\"  # Customize negative prompt\n",
        "\n",
        "    # Advanced settings\n",
        "    FRAMES = 73        # Longer video (7+ seconds)\n",
        "    FPS = 12          # Smoother playback\n",
        "    GUIDANCE = 7.0    # Higher prompt adherence\n",
        "    STEPS = 75        # Higher quality\n",
        "    SEED = 123        # Change for different results\n",
        "\n",
        "    print(\"üé® Custom generation settings:\")\n",
        "    print(f\"  üì∑ Image: {CUSTOM_IMAGE}\")\n",
        "    print(f\"  üìù Prompt: {CUSTOM_PROMPT}\")\n",
        "    print(f\"  üéûÔ∏è Frames: {FRAMES} ({FRAMES/FPS:.1f} seconds)\")\n",
        "    print(f\"  üéØ Guidance: {GUIDANCE}\")\n",
        "    print(f\"  ‚ö° Steps: {STEPS}\")\n",
        "    print(f\"  üé≤ Seed: {SEED}\")\n",
        "\n",
        "    # Generate custom video\n",
        "    custom_output = generator.generate_lofi_video(\n",
        "        image_path=CUSTOM_IMAGE,\n",
        "        prompt=CUSTOM_PROMPT,\n",
        "        negative_prompt=CUSTOM_NEGATIVE,\n",
        "        num_frames=FRAMES,\n",
        "        fps=FPS,\n",
        "        guidance_scale=GUIDANCE,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator_seed=SEED,\n",
        "        output_path=\"lofi_video_custom.mp4\"\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Custom video generated: {custom_output}\")\n",
        "    files.download(custom_output)\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Please upload an image first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips"
      },
      "source": [
        "## üí° Tips & Troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "memory_check"
      },
      "outputs": [],
      "source": [
        "# Check memory usage\n",
        "if torch.cuda.is_available():\n",
        "    memory_allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "    memory_reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "    memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "\n",
        "    print(f\"üíæ GPU Memory Status:\")\n",
        "    print(f\"  üìä Allocated: {memory_allocated:.1f} GB\")\n",
        "    print(f\"  üìã Reserved:  {memory_reserved:.1f} GB\")\n",
        "    print(f\"  üíΩ Total:     {memory_total:.1f} GB\")\n",
        "    print(f\"  üìà Usage:     {(memory_reserved/memory_total)*100:.1f}%\")\n",
        "\n",
        "    if memory_reserved > 12:\n",
        "        print(\"‚ö†Ô∏è  High memory usage! Consider:\")\n",
        "        print(\"   - Reducing num_frames\")\n",
        "        print(\"   - Reducing num_inference_steps\")\n",
        "        print(\"   - Restarting runtime\")\n",
        "\n",
        "# Clear memory if needed\n",
        "# torch.cuda.empty_cache()\n",
        "# import gc\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "examples"
      },
      "source": [
        "## üìö Example Prompts for Different Scenes\n",
        "\n",
        "### üå± Natural Landscapes\n",
        "- `\"Gentle wind moving through tall grass, soft morning light, peaceful nature scene\"`\n",
        "- `\"Tree branches swaying gently in the breeze, dappled sunlight filtering through leaves\"`\n",
        "- `\"Wildflowers swaying in a meadow, warm golden hour lighting\"`\n",
        "\n",
        "### üíß Water Scenes\n",
        "- `\"Calm lake with small ripples, reflecting clouds slowly drifting by\"`\n",
        "- `\"Gentle waves lapping on a pebble beach, soft sunset lighting\"`\n",
        "- `\"Rain drops creating ripples in a puddle, cozy atmosphere\"`\n",
        "\n",
        "### üå§Ô∏è Sky & Weather\n",
        "- `\"Clouds slowly drifting across a blue sky, peaceful day\"`\n",
        "- `\"Mist slowly rolling over hills, soft morning atmosphere\"`\n",
        "- `\"Gentle snowfall in a quiet winter scene\"`\n",
        "\n",
        "### üè† Cozy Scenes\n",
        "- `\"Steam rising from a hot cup, warm indoor lighting\"`\n",
        "- `\"Curtains gently swaying by an open window, soft breeze\"`\n",
        "- `\"Candle flame flickering softly, warm cozy atmosphere\"`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}